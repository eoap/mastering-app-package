{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Run the app-water-body-cloud-native.1.0.0.cwl released application package using calrissian, a CWL runner for kubernetes and exploit the usage report.\n",
    "\n",
    "## Lab\n",
    "\n",
    "This step has a dedicated lab available at /workspace/mastering-app-package/practice-labs/Kubernetes/benchmark.ipynb\n",
    "\n",
    "Select the Python kernel `.venv (Python 3.9.18)` from the top-right.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "import json\n",
    "import logging\n",
    "import unittest\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from calrissian.context import CalrissianLoadingContext, CalrissianRuntimeContext\n",
    "from calrissian.executor import ThreadPoolJobExecutor\n",
    "from calrissian.k8s import delete_pods\n",
    "from calrissian.main import (\n",
    "    activate_logging,\n",
    "    add_arguments,\n",
    "    flush_tees,\n",
    "    install_signal_handler,\n",
    ")\n",
    "from calrissian.report import (\n",
    "    CPUParser,\n",
    "    MemoryParser,\n",
    "    Reporter,\n",
    "    initialize_reporter,\n",
    "    default_serializer,\n",
    ")\n",
    "from calrissian.version import version\n",
    "from cwltool.argparser import arg_parser\n",
    "from cwltool.main import main as cwlmain\n",
    "from nose2.tools import params\n",
    "import uuid\n",
    "from cwltool.load_tool import fetch_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Create a Benchmark python class\n",
    "\n",
    "This Benchmark python class takes the application package parameters and the pair max cores/max ram.\n",
    "\n",
    "It will generate a benchmark report that can be analyzed to generate plots and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "class Benchmark():\n",
    "\n",
    "    def __init__(self, aoi, epsg, stac_items, bands, max_cores, max_ram):\n",
    "\n",
    "        self.level = logging.INFO\n",
    "        \n",
    "        self.cwl_url = \"https://github.com/eoap/mastering-app-package/releases/download/1.1.0/app-water-bodies-cloud-native.1.1.0.cwl\"\n",
    "\n",
    "        self.tmp_outdir_prefix = \"/calrissian/tmp\"\n",
    "        self.outdir = \"/calrissian/out\"\n",
    "\n",
    "        self.parser = arg_parser()\n",
    "\n",
    "        self.aoi = aoi \n",
    "        self.epsg = epsg \n",
    "        self.stac_items = stac_items\n",
    "        self.bands = bands \n",
    "        self.max_cores = max_cores\n",
    "        self.max_ram = max_ram\n",
    "\n",
    "    def get_cli_args(self):\n",
    "\n",
    "        cli_args = [\n",
    "            \"--tmp-outdir-prefix\",\n",
    "            self.tmp_outdir_prefix,\n",
    "            \"--outdir\",\n",
    "            self.outdir,\n",
    "            f\"{self.cwl_url}#water-bodies\",\n",
    "            f\"--aoi={self.aoi}\",\n",
    "            f\"--epsg={self.epsg}\"\n",
    "        ]\n",
    "\n",
    "        for stac_item in self.stac_items:\n",
    "            cli_args.append(f\"--stac_items={stac_item}\")\n",
    "\n",
    "        for band in self.bands:\n",
    "            cli_args.append(f\"--band={band}\")\n",
    "\n",
    "        return cli_args\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        parsed_args = self.parser.parse_args(\n",
    "            self.get_cli_args()\n",
    "        )\n",
    "\n",
    "        results, usage = self.run_calrissian(\n",
    "            parsed_args=parsed_args\n",
    "        )\n",
    "\n",
    "        _, workflowobj, uri = fetch_document(self.cwl_url)\n",
    "\n",
    "        result = {}\n",
    "\n",
    "        result[\"application_package\"] = {\"uri\": uri, \"cwl\": workflowobj}\n",
    "        result[\"results\"] = results\n",
    "        result[\"usage\"] = usage\n",
    "        result[\"parameters\"] = {\n",
    "            \"stac_items\": self.stac_items,\n",
    "            \"aoi\": self.aoi,\n",
    "            \"epsg\": self.epsg,\n",
    "            \"bands\": self.bands,\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def run_calrissian(self, parsed_args):\n",
    "\n",
    "        max_ram_megabytes = MemoryParser.parse_to_megabytes(self.max_ram)\n",
    "        max_cores = CPUParser.parse(self.max_cores)\n",
    "        executor = ThreadPoolJobExecutor(max_ram_megabytes, max_cores)\n",
    "        initialize_reporter(max_ram_megabytes, max_cores)\n",
    "\n",
    "        runtime_context = CalrissianRuntimeContext(vars(parsed_args))\n",
    "        runtime_context.select_resources = executor.select_resources\n",
    "\n",
    "        install_signal_handler()\n",
    "\n",
    "        stream_out = StringIO()\n",
    "\n",
    "        try:\n",
    "\n",
    "            res = cwlmain(\n",
    "                args=parsed_args,\n",
    "                stdout=stream_out,\n",
    "                executor=executor,\n",
    "                loadingContext=CalrissianLoadingContext(),\n",
    "                runtimeContext=runtime_context,\n",
    "                versionfunc=version,\n",
    "                logger_handler=logging.FileHandler(\"empty.log\"),\n",
    "            )\n",
    "        finally:\n",
    "            delete_pods()\n",
    "\n",
    "        assert res == 0\n",
    "\n",
    "        return json.loads(stream_out.getvalue()), Reporter.get_report().to_dict()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 run the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "benchmark = Benchmark(stac_items=[\n",
    "                \"https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20210708_0_L2A\",\n",
    "                \"https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_10TFK_20210713_0_L2A\",\n",
    "                \"https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20210718_0_L2A\",\n",
    "                \"https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20220524_0_L2A\",\n",
    "                \"https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20220514_0_L2A\",\n",
    "                \"https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20220504_0_L2A\",\n",
    "            ],\n",
    "            aoi=\"-121.399,39.834,-120.74,40.472\",\n",
    "            epsg=\"EPSG:4326\",\n",
    "            bands=[\"green\", \"nir\"],\n",
    "            max_cores=\"20\",\n",
    "            max_ram=\"128G\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "report = benchmark.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 analyze the report\n",
    "\n",
    "Plot a Gantt chart of the workflow steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_usage(report):\n",
    "    usage = report[\"usage\"]\n",
    "    cwl = report[\"application_package\"][\"cwl\"]\n",
    "\n",
    "    color_mapping = {}\n",
    "    for elem in cwl[\"$graph\"]:\n",
    "\n",
    "        if elem[\"class\"] in [\"CommandLineTool\"]:\n",
    "            color_mapping[elem[\"id\"]] = (\n",
    "                random.uniform(0, 1),\n",
    "                random.uniform(0, 1),\n",
    "                random.uniform(0, 1),\n",
    "            )\n",
    "\n",
    "    tasks = [step[\"name\"] for step in usage[\"children\"]]\n",
    "\n",
    "    node_colors = [\n",
    "        color_mapping.get(\"crop\")\n",
    "        if \"crop\" in task\n",
    "        else color_mapping.get(\"norm_diff\")\n",
    "        if \"norm_diff\" in task\n",
    "        else color_mapping.get(\"otsu\")\n",
    "        if \"otsu\" in task\n",
    "        else color_mapping.get(\"stac\", [0, 0, 0])\n",
    "        for task in tasks\n",
    "    ]\n",
    "\n",
    "    # Step 2: Create the data for the Gantt chart\n",
    "\n",
    "    start_dates = [step[\"start_time\"] for step in usage[\"children\"]]\n",
    "    durations = [step[\"elapsed_seconds\"] for step in usage[\"children\"]]\n",
    "\n",
    "    # Step 3: Initialize the figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Step 4: Set y-axis tick labels\n",
    "    ax.set_yticks(np.arange(len(tasks)))\n",
    "    ax.set_yticklabels(tasks)\n",
    "\n",
    "    # Step 5: Plot each task as a horizontal bar\n",
    "    for index, task in enumerate(tasks):\n",
    "        start_date = pd.to_datetime(start_dates[index])\n",
    "        end_date = start_date + pd.DateOffset(seconds=durations[index])\n",
    "        ax.barh(\n",
    "            index,\n",
    "            end_date - start_date,\n",
    "            left=start_date,\n",
    "            height=0.5,\n",
    "            align=\"center\",\n",
    "            color=node_colors[index],\n",
    "        )\n",
    "\n",
    "    # Step 6: Set x-axis limits\n",
    "    min_date = pd.to_datetime(min(start_dates))\n",
    "    max_date = pd.to_datetime(max(start_dates)) + pd.DateOffset(seconds=max(durations))\n",
    "    ax.set_xlim(min_date, max_date)\n",
    "\n",
    "    # Step 7: Customize the chart\n",
    "    ax.xaxis_date()\n",
    "    ax.xaxis.set_major_locator(mdates.WeekdayLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%dT%H:%M:%S\"))\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Steps\")\n",
    "    ax.set_title(\"Calrissian execution report\")\n",
    "\n",
    "    # Step 8: Display the chart\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "plot_usage(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "usage_df = pd.DataFrame.from_dict(report[\"usage\"][\"children\"])\n",
    "\n",
    "usage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "overall_report = copy.deepcopy(report[\"usage\"])\n",
    "\n",
    "del overall_report[\"children\"]\n",
    "\n",
    "\n",
    "pd.DataFrame.from_dict([overall_report])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
